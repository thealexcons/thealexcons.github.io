<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Writing Efficient Code - Performance Engineering Notes</title>


        <!-- Custom HTML head -->

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="01_intro.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="02_profiling.html"><strong aria-hidden="true">2.</strong> Profiling</a></li><li class="chapter-item expanded "><a href="03_modeling.html"><strong aria-hidden="true">3.</strong> Performance Modeling</a></li><li class="chapter-item expanded "><a href="04_efficiency.html" class="active"><strong aria-hidden="true">4.</strong> Writing Efficient Code</a></li><li class="chapter-item expanded "><a href="05_parallelism.html"><strong aria-hidden="true">5.</strong> Multi-Core Systems and Parallelism</a></li><li class="chapter-item expanded "><a href="06_device_performance.html"><strong aria-hidden="true">6.</strong> System and Device Performance</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Performance Engineering Notes</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="lecture-4-writing-efficient-code"><a class="header" href="#lecture-4-writing-efficient-code">Lecture 4: Writing Efficient Code</a></h1>
<p>Now that we know what a bottleneck is, how to identify one and model it, <strong>our challenge is build a system without a bottleneck</strong>, ie: one where all resources are equally utilised.
This is known as a <strong>balanced system</strong>.</p>
<p>Unfortunately, there is no such thing as a balanced system (only balanced sections of code). Different hardware optimisations have varying impact on code and therefore we say that balance is a function of code.</p>
<p>The <strong>fundamental tradeoff is between CPU and memory bandwidth efficiency</strong> and hence we distinguish between resource-bound code:</p>
<ul>
<li>Compute-bound</li>
<li>Memory-bound:
<ul>
<li>Latency-bound</li>
<li>Bandwidth-bound</li>
</ul>
</li>
</ul>
<p>We can influence these bottlenecks with different techniques, such as high-level techniques (choice of algorithm, memoisation, compression, etc.) and low-level techniques (our focus).</p>
<h2 id="compute-bound-code"><a class="header" href="#compute-bound-code">Compute-bound code</a></h2>
<p>Our primary objective is CPU efficiency. Generally, CPU-bound applications are those that:</p>
<ul>
<li>are poorly implemented</li>
<li>operate on small (cache-resident) datasets (ie: our bottleneck is not memory)</li>
<li>are math-heavy (esp. floating point math)</li>
<li>apply memory-oriented optimisations (ie: we have solved memory bottlenecks)</li>
</ul>
<p>Our <strong>target metric is wall clock time</strong>. Because wall clock time can be difficult to measure precisely, we often use certain proxy metrics such as stall cycles (caused by hazards) or CPI (cycles per instruction).</p>
<p><strong>Hazards</strong> cause stalls in the CPU pipeline and there are different types:</p>
<ul>
<li><strong>Control hazards</strong>: stalls due to data-dependent changes in the control flow (jumps and branches).</li>
<li><strong>Data hazards</strong>: stalls due to operands (data) not being available on time.</li>
<li><strong>Structural hazards</strong>: stalls due to a lack of physical execution resources (registers, execution ports/units, ...).</li>
</ul>
<p>We have already discussed hazards before (lecture 2) and they map nicely to the diagram below:</p>
<img src="assets/04_pipeline_hazards.png" width="500px">
<p>The ALU stall corresponds to a structural hazard, control hazards occur when no eligible instructions are ready (due to jumps) and abandonded instructions (due to misspeculation). Data stalls are caused by cache misses. Obviously, retired instructions are not hazardous.</p>
<p>Therefore, CPU optimisation is about mitigating these hazards and exploiting pipelined execution. Lets talk about some fundamental design decisions when it comes to pipelining.</p>
<h3 id="speculative-execution"><a class="header" href="#speculative-execution">Speculative execution</a></h3>
<p>Its purpose is to keep the pipeline full even if no instructions are eligible by executing instructions speculatively. This aims to address control hazards (branching). The other type of speculation is memory prefetching (covered in the memory-bound section below).</p>
<h3 id="superscalar-execution-dynamic-parallelism"><a class="header" href="#superscalar-execution-dynamic-parallelism">Superscalar execution (dynamic parallelism)</a></h3>
<p>The idea is to have multiple CPU pipelines within the same core. This means that different instructions can be in the same stage (eg: we can have two <code>MUL</code> instructions in the execution stage).</p>
<p>Modern CPUs tend to be four-way superscalar, ie: it has four different pipelines.</p>
<img src="assets/04_superscalar.png" width="400px">
<h3 id="out-of-order-execution"><a class="header" href="#out-of-order-execution">Out-of-order execution</a></h3>
<p>As a consequence of superscalar execution, out-of-order execution exploits the independence of instructions. </p>
<p>After decoding the instruction, the CPU will know if it has dependencies on other instructions or data. If instructions have <strong>no unsatisfied dependencies</strong>, it will move onto the execution stage directly. Therefore, we may execute instructions in a different order in which they arrive.</p>
<p>Out-of-order execution aims to address data and structural hazards.</p>
<h3 id="simd-static-parallelism"><a class="header" href="#simd-static-parallelism">SIMD (static parallelism)</a></h3>
<p>Another form of instruction-level parallelism is through SIMD instructions (Single Instruction Multiple Data). These instructions allow the CPU to perform the same operation on multiple data items at once, in a single cycle.</p>
<p>They use large specialised vector registers for different data types, allowing them to load multiple data items into a single register.</p>
<br>
<h3 id="improving-efficiency-with-partial-evaluation"><a class="header" href="#improving-efficiency-with-partial-evaluation">Improving efficiency with partial evaluation</a></h3>
<p>An important consideration to improving CPU efficiency is to write <strong>runtime predictable</strong> code for the critical path. We should evaluate code as early as possible and outside of the critical path whenever possible.</p>
<p>One technique is <strong>partial evaluation</strong> which consists of making the compiler work for you. We treat programs as multi-phased process. In every phase, you know more about the result so you can come up new programs that is more specialised tailored to the input. Examples are:</p>
<ul>
<li><strong>Function inlining</strong>: the compiler evaluates a function jump and places the code at the call site.</li>
<li><strong>JiT compilation</strong>: we start with higher level bytecode and compile it into native machine code.</li>
<li><strong>Symbolic programming</strong>: perform arithmetic on symbols rather than values (eg: <code>x/x</code> will always be 1).</li>
<li><strong>Constant expression evaluation</strong>: evaluate constant expressions at compile-time.</li>
</ul>
<p><strong>Example 1: constant evaluation</strong></p>
<pre><code class="language-c">int result(int input) {
  return input*3*5;
};

int result2(int input) {
  int three = 3-1;
  int five = 4+1;
  return input*three*five;
};

int three = 3;
int five = 5;
int result3(int input) {
  return input*three*five;
};
</code></pre>
<p>In <code>result2()</code>, the compiler figures out that variables <code>three</code> and <code>five</code> are always constant and replaces the operation with the values.</p>
<p>In <code>result3()</code>, the C compiler does not perform constant evaluation because it sees that <code>three</code> and <code>five</code> are variables available to other parts of the code and may be modified. It is important to understand the language semantics to know what constitutes a constant.</p>
<p><strong>Example 2: lifting expensive operations</strong></p>
<p>Any work that is executed often (such as in a loop) can be moved/lifted into a section where it executed seldomly. This can reduce control-flow hazards, since they now only occur once per loop rather than per iteration. A typical example is loop invariant motion, where we move loop invariant operations outside of the loop:</p>
<pre><code class="language-c">for (size_t i = 0; i &lt; N; i++) output[i] = 7*8;
</code></pre>
<p>becomes:</p>
<pre><code class="language-c">int tmp = 7*8; 
for (size_t i = 0; i &lt; N; i++) output[i] = tmp;
</code></pre>
<p>A related problem is <strong>loop specialisation</strong>. Suppose we want to scale a vector:</p>
<pre><code class="language-c">void scaleVector(int* input, size_t inputSize, int scale) {
  for(size_t i = 0; i &lt; inputSize; i++)
    input[i] *= scale;
}
</code></pre>
<p>The issue is that multiplications are quite expensive. Therefore, we can specialise the loop to avoid operations entirely (if <code>scale == 1</code>) or make them cheaper (use bit shifts).</p>
<pre><code class="language-c">void scaleVector2(int* input, size_t inputSize) {
  if(scale != 1) {    // avoid scale == 1 entirely
    if(scale == 2)
      (size_t i = 0; i &lt; inputSize; i++)
        input[i] &lt;&lt;= 1; // use cheap bitshift for scale == 2
    else
      (size_t i = 0; i &lt; inputSize; i++)
        input[i] *= scale;
  }
}
</code></pre>
<p>Unfortunately, this leads to code duplication. Instead, we can use metaprogramming to get the compiler to do the work for you. The idea here is to <strong>generate special cases at compile-time</strong> and apply optimisations for these cases. </p>
<p>C++ supports template metaprogramming and allows us to turn this...</p>
<pre><code class="language-c++">void scaleVector(int* input, size_t inputSize, int scale) {
  for(size_t i = 0; i &lt; inputSize; i++)
    input[i] *= scale;
};

int useIt(int* input, size_t size) {
  scaleVector(input, size, 2);
  scaleVector(input, size, 1);
  scaleVector(input, size, 0);
}
</code></pre>
<p>into this...</p>
<pre><code class="language-c++">template &lt;int scale&gt; void scaleVectorPE(int* input, size_t inputSize) {
  for(size_t i = 0; i &lt; inputSize; i++)
    input[i] *= scale;
};

int useIt(int* input, size_t size) {
  scaleVectorPE&lt;2&gt;(input, size);
  scaleVectorPE&lt;1&gt;(input, size);
  scaleVectorPE&lt;0&gt;(input, size);
}
</code></pre>
<p>Because the <code>scale</code> factor is known at compile-time, the compiler will be able to replace a multiplication by 2 with a bitshift, ignore the scale of 1 and set the input to 0 directly in the third case.</p>
<p>A useful pattern is to create a map that holds precomputed special cases for certain inputs. If the input is defined in the map, the precomputed result is obtained. Otherwise, we can resort to our runtime version of the function.</p>
<p><strong>Example 3: branch-free code</strong></p>
<p>We can go even further by writing branch-free code. We have seen how control-dependencies can cause hazards, such as below:</p>
<pre><code class="language-c">for(size_t i = 0; i &lt; inputSize; i++)
  if(input[i] &lt; high)
    output[outI++] = input[i];
</code></pre>
<p>We can be clever and manipulate how the <code>ouputI</code> index changes:</p>
<pre><code class="language-c">for(size_t i = 0; i &lt; inputSize; i++)
  output[outI] = input[i];
  outI += (size_t) (input[i] &lt; high);
</code></pre>
<p>We are now writing everything to the <code>output</code> array however we only move onto the next case if the condition holds. If it does not hold, <code>outI</code> does not change and the next value will overwrite the previous value (which is fine). In fact, this is beneficial for cache locality!
We can see the performance impact compared to the previous snippet (for a random array):</p>
<img src="assets/04_branch_free_graph.png" width="500px">
<p>We've converted this control dependency into a data dependency, so we need to be careful. If we find that branch missprediction is causing a problem, if-conversion is a good idea. Otherwise, it's probably not worth it (a lot of code is already very predictable, the case above is randomised). The bottom-line is: measure, then optimise!</p>
<p><strong>Example 4: SIMD vectorisation</strong></p>
<p>Compilers try to automatically vectorise your code. For a simple case like below...</p>
<pre><code class="language-c">for (size_t i = 0; i &lt; 1024; i++) out[i] = in1[i] * in2[i];
</code></pre>
<p>...the compiler will succeed. However, for more complicated cases we need to explicitly vectorise our code using intrinsics. Lets see an example below:</p>
<pre><code class="language-c++">#include &lt;immintrin.h&gt;

union v8f {    // either a float[8] or a SIMD word
  float floats[8];
  __m256 simdVec;
};

auto input1 = new int[bounds1]; // random data
auto input2 = new int[bounds2]; // random data

// Non-vectorised sum:
float sum = 0;
for (size_t i = 0; i &lt; bounds1; i++)
  sum += input2[input1[i]]


// Vectorised sum:
v8f sums{};
for (size_t i = 0; i &lt; bounds1 / 8; i++) {
  v8f values {
    // load values from memory using gather
    .simdVec = _mm256_i32gather_ps(input2, ((__m256i*)input1)[i], sizeof(int))
  };
  // perform addition directly on the simd register
  sums.simdVec = _mm256_add_ps(values.simdVec, sums.simdVec);
}
float sum = 0;
for (size_t i = 0; i &lt; 8; i++)
    sum += values.floats[i];
</code></pre>
<p>In the vectorised version, we obtain a x5 performance improvement than the scalar version. It is crucial that we keep our data in SIMD registers, otherwise we don't get the same benefits.</p>
<h2 id="memory-bound-code"><a class="header" href="#memory-bound-code">Memory-bound code</a></h2>
<p>Data hazards are caused by instructions that need to access data from memory but it results in a cache miss, producing a pipeline stall.
If the value has been accessed at some point previously, then this is called a <strong>capacity miss</strong>. Otherwise, this it is a <strong>compulsory miss</strong>.</p>
<p>Whenever we stall due to data hazards, we call the code <strong>memory-bound</strong>. We can be even more precise and describe two different situations whenever a stall occurs (due to data hazards):</p>
<ul>
<li><strong>Memory bandwidth bound</strong>: if the memory bus if fully utilised</li>
<li><strong>Memory latency bound</strong>: if the memory bus is not fully utilised</li>
</ul>
<p>We can apply different strategies based on the problem:</p>
<img src="assets/04_memory_bound_optimisation.png" width="300px">
<br>
<br>
<h3 id="compulsory-cache-misses"><a class="header" href="#compulsory-cache-misses">Compulsory cache misses</a></h3>
<p>Generally, the number of data-hazards (cache misses) when running a loop will be:</p>
<p>\(\frac{\text{data size}}{\text{cache line size}}\)</p>
<p>Luckily, CPUs support hardware prefetching whereby caches speculatively load the next cache line by recognising patterns and strides. This works well for regular memory accesses, but may break for irregular accesses like data-dependent accesses.</p>
<pre><code class="language-c">struct tuple { int x; int y; int z;};
int sumIt(tuple* input, long size, tuple* input2) {
  int sum = 0;
  for(size_t i = 0; i &lt; size; i++)
    sum += input2[input[i].x].y;

  return sum;
}
</code></pre>
<p>In the example above, the CPU knows the next cache line to be accessed for indexing into <code>input[i]</code> because it is a simple strided-accesses, however the index into <code>input2</code> is data-dependent. We can help the CPU through <strong>software prefetching</strong> via intrinsics:</p>
<pre><code class="language-c">struct tuple { int x; int y; int z;};
int sumIt(tuple* input, long size, tuple* input2) {
  int sum = 0;
  for(size_t i = 0; i &lt; size; i++){
    sum += input2[input[i].x].y;
    __builtin_prefetch(&amp;input2[input[i + 16].x]);
  }
  return sum;
}
</code></pre>
<p>We hint at the CPU that we are soon going to access the value within 16 iterations. Note that this happens <strong>asychronously</strong> at the hardware level.</p>
<h3 id="increasing-cache-line-utilisation"><a class="header" href="#increasing-cache-line-utilisation">Increasing cache-line utilisation</a></h3>
<p>Cache-line utilisation is defined as \(\frac{\text{data requested}}{\text{data loaded into cache}}\).
We can increase utilisation by changing the data layout in memory. We can change the <code>struct tuple</code> from the previous example to hold three arrays: one for <code>x</code>, <code>y</code> and <code>z</code>. This means that all <code>x</code>s are next to each other (and <code>y</code>s and <code>z</code>s):</p>
<pre><code class="language-c">struct tuple { int* x; int* y; int* z;};
int sumIt(tuple input, long size, tuple input2) {
  int sum = 0;
  for(size_t i = 0; i &lt; size; i++)
    sum += input2.y[input.x[i]];

  return sum;
}
</code></pre>
<p>This optimisation is called <em>Array-of-Structs</em> to <em>Struct-of-Arrays</em>.</p>
<h3 id="capacity-cache-misses"><a class="header" href="#capacity-cache-misses">Capacity cache misses</a></h3>
<p>Capacity-bound code suffers from <strong>thrashing</strong>: the larger the data we are accessing, the higher cost we are paying (because it doesn't fit in the cache).</p>
<p>This often happens when we have nested loops where we access two different regions of memory. A common solution to this issue is <strong>loop tiling</strong>, where we repeatedly access a cache line to keep it <em>hot</em>, so cache lines for one of the memory regions are never trashed.</p>
<p>(See lecture video at 1h 31m for good example)</p>
<br>
<p>In conclusion, if your code is:</p>
<ul>
<li><em>Bandwidth-bound</em>, then increase cache-line utilisation</li>
<li><em>Latency-bound</em>, then prefetch data</li>
<li><em>Capacity-bound</em>, then reduce the footprint/hot dataset</li>
</ul>
<h2 id="multicore-hazards-cache-coherency"><a class="header" href="#multicore-hazards-cache-coherency">Multicore hazards: cache coherency</a></h2>
<p>A final type of hazard to be aware about in a multicore environment is <strong>cache coherency</strong>. Whenever one core modifies a value in its cache, it needs to be updated in the other cores' caches. </p>
<p>Intel x86 CPUs have a QPI bus (Quick Path Interconnect) that connects caches directly to avoid having to go through the memory bus for cache coherency updates.</p>
<p>The cache coherency protocol used by most modern CPUs is <strong>MESI</strong>, which describes four different states in which a cache line can be in:</p>
<img src="assets/04_mesi.png" width="400px">
<ul>
<li><strong>Exclusive</strong>: a single core exclusively holds a cached copy of some data in its cache.</li>
<li><strong>Shared</strong>: when another core accesses the data, it creates a copy in its core and the cache line becomes shared.</li>
<li><strong>Modified</strong>: when one of the cores modifies the data, the state of the cache line in its core becomes modified.</li>
<li><strong>Invalid</strong>: the other cores' same cache lines become invalid.</li>
</ul>
<br>
<h2 id="tutorial-notes"><a class="header" href="#tutorial-notes">Tutorial notes</a></h2>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="03_modeling.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="05_parallelism.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="03_modeling.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="05_parallelism.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script type="text/javascript">
            var socket = new WebSocket("ws://localhost:3000/__livereload");
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->


    </body>
</html>
